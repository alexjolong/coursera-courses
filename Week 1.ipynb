{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1\n",
    "## Model and Cost Function\n",
    "### Model Representation\n",
    "\n",
    "Using *(x(i), y(i))* to denote *ith* item of a set, where *x(i)* is the *ith* input variable and *y(i)* is the *ith* output variable.\n",
    "\n",
    "Also, *i* in this context counts from 1\n",
    "\n",
    "y = h(x)\n",
    " * h originally stood for \"hypothesis\"\n",
    "\n",
    "Univariate linear regression = just one variable.\n",
    "\n",
    "X and Y denote the space of input and output values, respectively.\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "*(hw)(x) = (w0) + (w1)x*\n",
    " * w's are used here in place of 'theta'. *hw* is the hypothesis at the value set theta.\n",
    " \n",
    "Minimization problem:\n",
    "Minimize w0 w1. \n",
    "\n",
    "Solution:\n",
    "choose weights such that the hypothesized value of *hw(x)* is close to y for the training exmaples *(x,y)*. I.e. pick weights that give you a similar output as *hw(x)*\n",
    "sum from 1 to m of *(hw(x(i)) - y(i))^2*\n",
    " * When m is the number of your training examples, this will give you the square of the total difference between the trained solution's output and hypothetical solution's output for all training inputs. You want to minimize this.\n",
    " * However, to make things easier, divide it by 2m. This will give you a smaller number but minimizing it still works as a heuristic.\n",
    " * In other words, \"find me the weights which cause the differences between their formula output and the real example's output is minimized\"\n",
    " \n",
    "This is also known as the Squared Error Function.\n",
    " * Why do we square? My intuition is to minimize smaller errors and maximize larger ones. Basis: wider margins of error are proportionally worse to medium margins than medium are to small.\n",
    " \n",
    "### Cost Function Intuition 1\n",
    "Ahh, we also square because we are minimizing the magnitude of the error, not the error itself (or we would make our weights negative for positive inputs). Why not just take the max value? Perhaps this is less computationally expensive.\n",
    "\n",
    "J(0) = 1/6 ((0 - 1)^2 + (0 - 2)^2 + (0 - 3)^2)\n",
    "J(0) = 1/6 (1 + 4 + 9)\n",
    "J(0) = 14/6\n",
    "\n",
    "### Cost Function Intuition 2\n",
    "I understand everything now.\n",
    "\n",
    "The 3D cost function for 2 weights is super dope. I wish I had these types of visuals when I was learning calculus.\n",
    "\n",
    "## Parameter Learning\n",
    "### Gradient Descent\n",
    "A general algorithm, good at minimizing a function *J(w0, w1)*. Works for greater dimensional equations as well.\n",
    "\n",
    "*min J(w1, ..., wn)*\n",
    "\n",
    "Steps:\n",
    "1. Start with some w0, w1\n",
    "2. Keep changing w0, w1 to reduce *J(w0, w1)* until we hopefully end up at a minimum (hopefully not a local one!)\n",
    "\n",
    "\"For the value of the coordinates I am at (values of w), and the values of w surrounding me, which is smallest?\"\n",
    "\n",
    "*wj := wj - a(d/d(wj) J(w0, w1))* (for j=0 and j=1)\n",
    " * a := b means assign the value of b to 1.\n",
    " * a = learning rate (the amount of step we take. Large alphas = large steps).\n",
    " * (d/d(wj)) is a derivative in terms of wj\n",
    " * Note that because we are taking the derivative of both j=1 and j=0, we need to simultaneously update wj (both w0 and w1). This 'simultaneousness' means that we cannot update w0 before it is used in the equation to calculate w1. Otherwise the algorithm might behave strangely.\n",
    "\n",
    "temp0 = 1 + sqrt(2)\n",
    "temp1 = 2 + sqrt(2)\n",
    "w0 = temp0 = 1 + sqrt(2)\n",
    "w1 = temp1 = 2 + sqrt(2)\n",
    "\n",
    "### Gradient Descent Intuition\n",
    "Minimize *J(w1)* when *w1* is a real number.\n",
    "Derivative of *J(w1)* is the tangent to the slope of *J* at point *w1*.\n",
    "If the derivative is positive, we are subtracting that (times the learning rate) from *w1*. We are adding if the derivative is positive. This will drive us to the lowest point in the graph of *J*.\n",
    "\n",
    " * No need to decrase *a* over time, because the derivative will naturally decrease as the slope becomes shallower.\n",
    "\n",
    "### Gradient Descent for Linear Regression\n",
    "Cost function for linear regression will always be \"bowl\" shaped. Because the linear regression algebra is a Convex Function.\n",
    " * This means there won't be any local minima other than the global minimum! Right?? -- Yes\n",
    "\n",
    "AKA \"Batch\" gradient descent, meaning that each step of gradient descent computes the sum over all of the training examples. \n",
    "\n",
    "Also, gradient descent scales to larger datasets better than the Normal Equations method.\n",
    "\n",
    "### Quiz\n",
    "5 / 5 (100%)\n",
    "\n",
    "\n",
    "## Linear Algebra Review\n",
    "### Matrices and Vectors\n",
    "Matrix: Rectangular array of numbers\n",
    "Dimension of matrix: rows X columns\n",
    "R(4x2) means \"Matrix of the set of matrices which have 4 rows and 2 columns\"\n",
    "A(ij) means \"Entry at the *ith* row and *jth* column of matrix A\"\n",
    "Vector: n X 1 matrix (n-dimensional)\n",
    "R(4) means \"Vector of the set of 4-dimensional vectors\"\n",
    "y(i) means \"Entry at the *ith* dimension of vector y\"\n",
    "\n",
    "1-indexed and 0-indexed:\n",
    " * Assume we are using 1-indexed vectors unless specified otherwise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
