{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5\n",
    "## Cost Function and Backpropogation\n",
    "### Cost Function\n",
    "\n",
    "### Backpropogation Algorithm\n",
    "For one training example (x,y):\n",
    "compute the activation values for each node in the first layer\n",
    "compute the second layer input values z = theta * a\n",
    "Do this for every layer\n",
    "\"Backpropogation\" - for each node j in layer y, we will calculate the error from our desired activation.\n",
    "    Note that for the last layer, this error is just the value minus the actual value of the training example (y). However, for earlier layers, the error is the value minus the desired input to the next layer. Also note that the first layer doesn't have any error (how could it be incorrect? these are the inputs).\n",
    "    \n",
    "For all m training examples (xi, yi):\n",
    "Build an array of deltas, initially 0, for all i j and m.\n",
    "do forward propogation\n",
    "use yi to do backpropogation on the network for one example.\n",
    "Delta\\[i,j\\] for one example is the activation of that node times the error of the next layer.\n",
    "\n",
    "We multiply the theta matrix of layer l and the delta values of the next layer, in order to compute the delta values of layer l.\n",
    "Then we do element-wise multiplication of the result with the derivative of the activation values for that layer. \n",
    "With vectorization, we compute this derivative by multiplying the delta values of layer l+1 with the transpose of the activation of l. delta(l+1) * a(l)'\n",
    "We accumulate these derivatives in a Delta matrix given by 1/m(delta\\[i,j,l\\] + lambda * theta\\[i,j,l\\]). We drop the theta term if j=0 (first layer).\n",
    "\n",
    "### Backpropogation Intuition\n",
    "I thought I understood backpropogation. In fact, I was a bumbling fool.\n",
    "\n",
    "## Backpropogation in Practice\n",
    "### Implementation Note: Unrolling Parameters\n",
    "Cost function and optimization algorithms receive an initial theta variable, which they assume to be a vector in the space R(n+1).\n",
    "\n",
    "For a neural network, parameters are matrices, not vectors. In addition, the gradients that are returned are matrices instead of vectors.\n",
    "\n",
    "This code: thetaVec = \\[ Theta1(:); Theta2(:); Theta3(:)\\];\n",
    "DVec = \\[D1(:); D2(:); D3(:)\\];\n",
    "\n",
    "Turns the theta matrices into one vector.\n",
    "\n",
    "You can go from vector back to matrix representation by using reshape(thetaVector(start:end), rows,cols)\n",
    "\n",
    "### Gradient Checking\n",
    "derivative approximation:\n",
    "gradApprox = (J(theta + EPSILON) - J(theta - EPSILON)) / (2 * EPSILON)\n",
    "((1.01)^3 - (.99)^3) / .02 = 3.0001\n",
    "\n",
    "If theta is a vector (unrolled version of theta matrices), then we can find the derivative of each theta value with:\n",
    "J(theta) = (J(theta1, theta2, ... thetan + EPSILON, ...) - J(theta1, theta2, ... thetan - EPSILON, ...)) / 2 * EPSILON\n",
    "\n",
    "^ Do the above for all n, and store the results in a vector. The vector should be approximately equivalent to that generated by backpropogation.\n",
    "\n",
    " - Gradient Checking is fairly expensive. More computationally expensive than backpropogation. So you should only do it as a check.\n",
    "\n",
    "### Random Initialization\n",
    "To initialize a matrix to random values within the range \\[-EPSIlON, EPSILON\\], \n",
    "do r = rand(m,n) * (2 * EPSILON) - EPSILON\n",
    "\n",
    "### Putting It Together\n",
    "How do we choose the parameters / hyperparameters of a neural network?\n",
    " - # input units = dimension of features (x(i))\n",
    " - # of output units = number of classes\n",
    " - reasonable default is a network with just one hidden layer. If there are more than one hidden layers, then usually there is the same number of hidden units in each layer. More hidden units is usually better.\n",
    " \n",
    "Steps to training a neural network.\n",
    " - Randomly initialize weights\n",
    " - Forward propogate to get h(x) for any x (vector)\n",
    " - Impliment cost function J(theta)\n",
    " - Impliment backpropogation to compute partial derivative of J(theta) for all theta.\n",
    " - Perform each iteration of for/backprop on one training example.\n",
    " - Use gradient checking to check your derivatives.\n",
    " - Use gradient descent or advanced optimization method with backprop to minimize J(theta) as a function of theta.\n",
    " -- It is possible to get stuck at local minima, but unlikely.\n",
    " - J(theta) should be decreasing (or at least nonincreasing) at every iteration\n",
    "\n",
    "### Autonomous Driving Example\n",
    "\n",
    "## Quiz\n",
    "5/5 (100%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
