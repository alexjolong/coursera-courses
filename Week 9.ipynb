{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 9 - Anomaly Detection\n",
    "## Density Estimation\n",
    "### Problem Motivation\n",
    "- Anomaly detection is a hybrid between unsupervised and supervised learning.\n",
    "- Application: features of aircraft engines such as heat generated, vibration intensity, etc.\n",
    "- For any new (test) engine, we want to know if it is anomalous in any way.\n",
    "- Need to define some epsilon which is a value, above which a classification will be marked as anomolous.\n",
    "\n",
    "### Gaussian Distribution\n",
    "- AKA normal distribution\n",
    "- I'm pretty sure i know this... but I'll watch anyway (at 1.5x)\n",
    "x ~ N(mu,sigma^2)\n",
    "- This means that x is a distributed Gaussian with mean mu and variance sigma^2\n",
    "p(x; mu, sigma^2) = 1/(sqrt(2* pi) * sigma) * exp(-(x-mu)^2 / 2(sigma^2))\n",
    "- As sigma increases, the distribution becomes \"fatter\"\n",
    "- As mu increases, the x offset of the distribution increases\n",
    "\n",
    "### Algorithm\n",
    "- For a training set {x1, x2, ..., xm}, p(x) = the product of p(xi;mui,sigmai^2) for all i, where i is a feature across the entire set\n",
    "\n",
    "steps:\n",
    "1. Choose features xi that might be indicative of anomalous examples\n",
    "2. Fit parameters mu1, ..., mun, sigma1^2, ..., sigman^2\n",
    "muj = 1/m * SUM(i=1:m)(xj^i)\n",
    "sigmaj^2 = 1/m * SUM(i=1:m)(xj^i - muj)^2\n",
    "3. Given new example x, compute p(x)\n",
    "p(x) = PRODUCT(p(xj; muj, sigmaj^2)\n",
    "4. x is anomalous is p(x) < epsilon\n",
    "\n",
    "\n",
    "## Building an Anomaly Detection System\n",
    "### Developing and Evaluating an Anomaly Detection System\n",
    "- How do we evaluate our algorithm (how well it performs at detecting anomalies)\n",
    "- Assume we have labeled data, y=0 if normal, y=1 if anomalous\n",
    "- We will likely have very sparse anomalous examples\n",
    "- Only put good examples in the training set. Put half of your anomalous examples in CV, half in test.\n",
    "- On CV and test, y=1 if p(x)< epsilon (anomaly), y=0 if p(x) >= epsilon (normal)\n",
    "\n",
    "Possible evaluation metrics: \n",
    "- true positive, false positive, false neg, true neg\n",
    "- Precision/Recall\n",
    "- F1-score\n",
    "\n",
    "Since data is very skewed, classification accuracy is not a good metric. An algorithm that always predicts normal might perform very well, but not when needed.\n",
    "\n",
    "- Note that we can also use the cross validation to test and choose the parameter epsilon.\n",
    "\n",
    "### Anomaly Detection vs Supervised Learning\n",
    "- When to use which?\n",
    "- Anomaly:\n",
    "- - When there is avery small number of positive examples (0-20 is common)\n",
    "- - If there are many different \"types\" of anomalies. Hard for any algorithm to learn from positive examples what the anomalies look like.\n",
    "- - Common cases: fraud detection, manufacturing, machine monitoring\n",
    "- Supervised learninig:\n",
    "- - When there are a large number of both positive and negative examples\n",
    "- - When there are enough positive examples (anomalies) to learn what they might look like.\n",
    "- - spam classification, weather prediction\n",
    "\n",
    "### Choosing what features to use\n",
    "- If features are non-gaussian, the algorithm will often work just fine, but we would prefer to transform the data.\n",
    "- - for instance, we can take a log(x) transformation.\n",
    "- - you can also take x^a where a is some fraction.\n",
    "\n",
    "- Look at the data and see if it inspires you to create new features.\n",
    "- Features should either take on very large or very small values in the event of an anomaly\n",
    "\n",
    "## Quiz\n",
    "4/5 (80%)\n",
    "\n",
    "\n",
    "# Week 9 - Recommender Systems\n",
    "## Predicting Movie Ratings\n",
    "### Problem Formulation\n",
    "- Recommender systems are some of the most important (i.e. commonly used) applications of machine learning\n",
    "- Responsible for substantial fractions of amazon, netflix, and other companies revenues.\n",
    "- Interestingly, doesn't receive a lot of attention in academic literature.\n",
    "\n",
    "Values in a recommender systems problem:\n",
    "nu = # of users\n",
    "nm = # of movies\n",
    "r(i,j) = 1 if user j has rated movie i\n",
    "y(i,j) = rating given y user j to movie i. Range between 0:5\n",
    "\n",
    "### Content Based Recommendations\n",
    "- Define a set of features which represent movie \"content\". Individual movies might have unique weights for each feature.\n",
    "- n = # of features\n",
    "\n",
    "To make predictions, we could do the following:\n",
    "1. for each user j, learn parameter vector theta(j). (we'll get to how this can be done)\n",
    "2. Predict user j as rating movie i with theta(j)' * x(i) stars\n",
    "\n",
    "Then we just do usual linear regression (using least squares). Except we sum the objective over all users. I.e. two sums - one across all features, one across all users.\n",
    " - Add in regularization, just 4 fun.\n",
    " \n",
    "Then do gradient descent on the derivative of our objective * a learning rate.\n",
    "\n",
    "### Collaborative Filtering\n",
    "\n",
    "\n",
    "\n",
    "### Low Rank Matrix Factorization\n",
    "\n",
    "\n",
    "## Quiz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
